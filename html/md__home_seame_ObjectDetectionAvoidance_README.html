<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Object Detection: Object Detection and Avoidance</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="doxyfile.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Object Detection
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Object Detection and Avoidance </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Training a Yolo Object detection model, with <b>Lane detection (segmentation)</b> as well.</p>
<p><img src="Fluxograma.jpg" alt="" class="inline" title="Project Structure"/></p>
<h1><a class="anchor" id="autotoc_md8"></a>
Inference Result</h1>
<p>Carla dataset, Yolo predicting validation images</p>
<p><img src="models/yolo-lane-seame-unfroze/val_batch2_pred.jpg" alt="Project Structure" class="inline"/></p>
<p>Yolo model predicting validation seame lab images</p>
<p><img src="models/yolo-lane-seame-unfroze/val_batch0_pred.jpg" alt="Project Structure" class="inline"/></p>
<p>This image is a result of running <em><a class="el" href="testing_8py.html">testing.py</a></em>, so running predict() of our model. The <b>lane points</b> (polygons, mask) are in blue.</p>
<h1><a class="anchor" id="autotoc_md9"></a>
Datasets</h1>
<p>The datasets we used to train/validate are from: <a href="https://onedrive.live.com/?id=4EF9629CA3CB4B5E%213022&amp;cid=4EF9629CA3CB4B5E&amp;redeem=aHR0cHM6Ly8xZHJ2Lm1zL3UvcyFBbDVMeTZPY1l2bE9sMDQxNHNSb3BGVkgyOTVXP2U9Q2pjbDYy">Link to dataset</a>. We used dataset8 and also some images we took of our lab.</p>
<p>I noticed a decay of object detection outside the objects of my dataset, despite the fact that i froze the backbone and lowered the learning rate. So you might need to add some object images to preserve more information if you have a big dataset and train with a lot of epochs.</p>
<h2><a class="anchor" id="autotoc_md10"></a>
Roboflow</h2>
<p>To create the masks of our lab images, we used Roboflow to generate the annotations, then we added blur, noise and grayscale to the images and resized them, keeping the aspect ratio. After this, we downloaded to <b>COCO segmentation</b> format. This creates a Json file with all the annotations. So, in <em><a class="el" href="coco__txt_8py.html">scripts/coco_txt.py</a></em> we convert these annotations, that have the polygons of the lanes into binary masks, so we can then convert them back to normalized polygons and save them to a txt file. We tried to convert the COCO polygons directly to yolo-seg txt format but we noticed some weird values and loss of information. Therefore, converting first to binary masks helped preserve the lane shape.</p>
<p>We also downloaded some Roboflow datasets of road objects, such as cross walks, street signs and so on, to add to our object detection Yolo model.</p>
<h1><a class="anchor" id="autotoc_md11"></a>
Creating Annotations</h1>
<p>In the scripts directory file <em><a class="el" href="create__annotations_8py.html">create_annotations.py</a></em> we create the <b>annotation labels</b> for lane and object detection. How do we do this? We pass our images through a pre-trained <b>Yolo11-seg model</b>, to get the object polygons. Then, we use <b>supervision</b> tools to convert the lane <b>binary masks</b> to valid Yolo <b>polygons</b>. Finaly, we <b>merge</b> the object and lane annotations and get the label files.</p>
<p>Be attentive towards the size of the images and masks, we decided to keep the images square, (training and testing), for compatibility. In the scripts directory, file <em><a class="el" href="resize_8py.html">resize.py</a></em> you can resize images with <b>letterboxing</b> (keeping <b>aspect ratio</b>), or not.</p>
<p>In these scripts, you might need to change some function <b>parameters</b>, the original size of the images, and the <b>paths</b> to the images, so that it correctly links to your dataset and original size of your images.</p>
<p>For debugging, you can <b>visualize the annotations</b> in <em><a class="el" href="visual__annotations_8py.html">scripts/visual_annotations.py</a></em>.</p>
<h1><a class="anchor" id="autotoc_md12"></a>
Training and Testing</h1>
<p>In <em><a class="el" href="training_8py.html">training.py</a></em> (scripts directory) where we are retraining our model, we set the augmentations to None since it disrupts our images, and add other augmentations that dont disrupt them, such as brightness, saturation and hue. After the first training where we freeze the backbone, you train again to unfreeze everything.</p>
<p>For testing, (in <em><a class="el" href="testing_8py.html">scripts/testing.py</a></em>), we call our trained model and set it to <b>predict</b>, to test the prediction of a given validation image.</p>
<h1><a class="anchor" id="autotoc_md13"></a>
Jetson Nano</h1>
<p>In Jetson, we have an ultralytics Yolo <b>container</b>, specific for compatibility with Jetson Nano. This container only runs a yolo model above or equal to version 8. In here we will run our Yolo with lane detection.</p>
<p>We have a self-hosted jetson runner, so that everytime I push the code to github, it will deploy my models to jetson, this code is in *.github/deploy_jetson.yml*.</p>
<h1><a class="anchor" id="autotoc_md14"></a>
Documentation</h1>
<p>For more documentation click here: <a href="https://seame-pt.github.io/ObjectDetectionAvoidance/html/index.html">Doxygen</a>. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
